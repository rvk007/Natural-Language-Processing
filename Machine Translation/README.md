# Machine Translation

## Transformer BERT

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZGSkMq_sDkQ-aGxt-AA5r7ZBlXAH4xd_?usp=sharing)

Results:

- Validation Loss: 1.613
- Validation perplexity: 5.016
- Bleu score: 35.33

Hyperparameters:

- Epochs: 10
- Loss function: CrossEntropy
- Optimizer: Adam
- Learning Rate: 0.0005

## Attention Mechanism and CNN

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1FdtystGuMkFx1cIKrZbqTP2AhqonM0zp?usp=sharing)

Results:

- Validation Loss: 1.73
- Validation perplexity: 5.64
- Bleu score: 33.31

Hyperparameters:

- Epochs: 10
- Loss function: CrossEntropy
- Optimizer: Adam
- Learning Rate: 0.001

## LSTM and Fully Connected Layers

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1cm_rUGLEA0sYkcav6DcJHO_ONSCQ2sa9?usp=sharing)

Results:

- Validation Loss: 3.76
- Validation perplexity: 42.87

Hyperparameters:

- Epochs: 10
- Loss function: CrossEntropy
- Optimizer: Adam
- Learning Rate: 0.001
